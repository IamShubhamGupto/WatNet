{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deeplabv3_plus.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWGEgllt58hV8CdXhX04FZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1SyzI8U5ftF","executionInfo":{"status":"ok","timestamp":1622818839538,"user_tz":-480,"elapsed":457,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"0b2a56cf-29d0-4d02-c81a-14be1b9e422d"},"source":["# ### mount on google drive\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# import os\n","# os.chdir(\"/content/drive/My Drive/WatNet\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Q7W6g4e5T9c","executionInfo":{"status":"ok","timestamp":1622818866595,"user_tz":-480,"elapsed":414,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"2a5bf27d-d860-4417-fc6e-23daec26358f"},"source":["# %%writefile model/seg_model/deeplabv3_plus.py\n","\n","\"\"\"\n","@Reference: https://github.com/luyanger1799/amazing-semantic-segmentation\n","\"\"\"\n","import os\n","import sys\n","sys.path.append(os.getcwd())\n","import tensorflow as tf\n","import tensorflow.keras.layers as layers\n","import tensorflow.keras.models as models\n","import tensorflow.keras.backend as backend\n","from model.base_model.xception import Xception\n","\n","class GlobalAveragePooling2D(layers.GlobalAveragePooling2D):\n","    def __init__(self, keep_dims=False, **kwargs):\n","        super(GlobalAveragePooling2D, self).__init__(**kwargs)\n","        self.keep_dims = keep_dims\n","    def call(self, inputs):\n","        if self.keep_dims is False:\n","            return super(GlobalAveragePooling2D, self).call(inputs)\n","        else:\n","            return backend.mean(inputs, axis=[1, 2], keepdims=True)\n","\n","class Concatenate(layers.Concatenate):\n","    def __init__(self, out_size=None, axis=-1, name=None):\n","        super(Concatenate, self).__init__(axis=axis, name=name)\n","        self.out_size = out_size\n","    def call(self, inputs):\n","        return backend.concatenate(inputs, self.axis)\n","\n","class deeplabv3_plus(tf.keras.Model):\n","    def __init__(self, nclasses, base_model='Xception-DeepLab', **kwargs):\n","        super(deeplabv3_plus, self).__init__(**kwargs)\n","        \"\"\"\n","        The initialization of DeepLabV3Plus.\n","        :param num_classes: the number of predicted classes.\n","        :param version: 'DeepLabV3Plus'\n","        :param base_model: the backbone model\n","        :param kwargs: other parameters\n","        \"\"\"\n","        dilation = [1, 2]\n","        self.base_model = base_model\n","        self.nclasses = nclasses\n","        self.dilation = dilation\n","        self.encoder = Xception(version=base_model, dilation=dilation)\n","\n","    def call(self, inputs):\n","        nclasses = self.nclasses\n","        _, h, w, _ = backend.int_shape(inputs)\n","        self.aspp_size = (h // 16, w // 16)\n","        c2, c5 = self.encoder(inputs, output_stages=['c1', 'c5'])\n","\n","        x = self._aspp(c5, 256)\n","        x = layers.Dropout(rate=0.5)(x)\n","\n","        x = layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(x)\n","        x = self._conv_bn_relu(x, 48, 1, strides=1)\n","\n","        x = Concatenate(out_size=self.aspp_size)([x, c2])\n","        x = self._conv_bn_relu(x, 256, 3, 1)\n","        x = layers.Dropout(rate=0.5)(x)\n","\n","        x = self._conv_bn_relu(x, 256, 3, 1)\n","        x = layers.Dropout(rate=0.1)(x)\n","        if nclasses == 2:\n","            x = layers.Conv2D(1, 1, strides=1, activation= 'sigmoid')(x)\n","        else:\n","            x = layers.Conv2D(nclasses, 1, strides=1, activation='softmax')(x)\n","        x = layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(x)\n","        outputs = x\n","        return outputs\n","        # return models.Model(inputs, outputs, name='deeplabv3_plus')\n","\n","    def _conv_bn_relu(self, x, filters, kernel_size, strides=1):\n","        x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n","        x = layers.BatchNormalization()(x)\n","        x = layers.ReLU()(x)\n","        return x\n","\n","    def _aspp(self, x, out_filters):\n","        xs = list()\n","        x1 = layers.Conv2D(out_filters, 1, strides=1)(x)\n","        xs.append(x1)\n","\n","        for i in range(3):\n","            xi = layers.Conv2D(out_filters, 3, strides=1, padding='same', dilation_rate=6 * (i + 1))(x)\n","            xs.append(xi)\n","        img_pool = GlobalAveragePooling2D(keep_dims=True)(x)\n","        img_pool = layers.Conv2D(out_filters, 1, 1, kernel_initializer='he_normal')(img_pool)\n","        img_pool = layers.UpSampling2D(size=self.aspp_size, interpolation='bilinear')(img_pool)\n","        xs.append(img_pool)\n","\n","        x = Concatenate(out_size=self.aspp_size)(xs)\n","        x = layers.Conv2D(out_filters, 1, strides=1, kernel_initializer='he_normal')(x)\n","        x = layers.BatchNormalization()(x)\n","        return x\n","\n","input = tf.ones([4, 256, 256, 4],tf.float32)\n","# input = layers.Input(shape=(256,256,3))\n","model = deeplabv3_plus(nclasses=2)\n","oupt = model(inputs=input)\n","print(oupt.shape)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Overwriting model/seg_model/deeplabv3_plus.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOMcDoUS5eNL","executionInfo":{"status":"ok","timestamp":1622814585366,"user_tz":-480,"elapsed":519,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"be66853a-1c34-4922-f786-613401352804"},"source":[""],"execution_count":36,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n"],"name":"stdout"}]}]}